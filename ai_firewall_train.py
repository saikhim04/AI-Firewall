import numpy as np
import pandas as pd
import torch
import torch.nn as nn
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report
from scapy.all import sniff, IP
from sklearn.metrics import f1_score, precision_recall_curve
import joblib, json, csv, time, os
import csv, time, os
from collections import Counter
from scapy.layers.inet import TCP, UDP
from sklearn.metrics import confusion_matrix, classification_report

# 1) Load data
df = pd.read_csv("ai_firewall_dataset.csv")
X = df.drop("label", axis=1).values
y = df["label"].values

# 2) Split ‡∏Å‡πà‡∏≠‡∏ô ‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡πà‡∏≠‡∏¢ fit scaler ‡∏î‡πâ‡∏ß‡∏¢ train set ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test  = scaler.transform(X_test)

# 3) Tensor
X_train = torch.tensor(X_train, dtype=torch.float32)
y_train = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)
X_test  = torch.tensor(X_test,  dtype=torch.float32)
y_test  = torch.tensor(y_test,  dtype=torch.float32).view(-1, 1)


# 4) Model (‡πÑ‡∏°‡πà‡πÉ‡∏™‡πà Sigmoid ‚Äî ‡∏à‡∏∞‡πÉ‡∏ä‡πâ BCEWithLogitsLoss)
class FirewallNN(nn.Module):
    def __init__(self, in_features):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(in_features, 64),
            nn.ReLU(),
            nn.Linear(64, 32),
            nn.ReLU(),
            nn.Linear(32, 1)   # <- no Sigmoid here
        )

    def forward(self, x):
        return self.net(x)

model = FirewallNN(in_features=X_train.shape[1])
# ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì weight ‡∏Ç‡∏≠‡∏á class (‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• y_train ‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô tensor)
y_np = y_train.numpy().ravel().astype(int)
pos = (y_np == 1).sum()  # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á class 1 (ALLOW)
neg = (y_np == 0).sum()  # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á class 0 (DENY)

# pos_weight = ‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡πÉ‡∏´‡πâ class 1 ‡∏°‡∏µ‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô
ratio = neg / max(pos, 1)
pos_weight = torch.tensor([1.2 * ratio], dtype=torch.float32) # ‡∏à‡∏≤‡∏Å 1.0*ratio --> 0.8*ratio

# ‡πÉ‡∏ä‡πâ BCEWithLogitsLoss ‡πÅ‡∏ó‡∏ô BCELoss (‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£‡∏Å‡∏ß‡πà‡∏≤)
criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)
optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)
#optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
#optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)

# 5) Train
for epoch in range(600):
    model.train()
    optimizer.zero_grad()
    logits = model(X_train)
    loss = criterion(logits, y_train)
    loss.backward()
    optimizer.step()
    if epoch % 20 == 0:
        print(f"Epoch {epoch}, Loss: {loss.item():.4f}")

# 6) Evaluate + pick best threshold + report + save (single clean block)
model.eval()
with torch.no_grad():
    # predict prob on test
    logits_test = model(X_test)
    probs = torch.sigmoid(logits_test).cpu().numpy().ravel()

# y_true as numpy
y_true_np = y_test.cpu().numpy().astype(int).ravel()

# find best threshold by F1
prec, rec, ths = precision_recall_curve(y_true_np, probs)
f1s = 2 * (prec * rec) / (prec + rec + 1e-9)
best_idx = int(np.nanargmax(f1s))
THRESH = float(ths[best_idx]) if best_idx < len(ths) else 0.5

print(f"Best threshold‚âà{THRESH:.3f}, P={prec[best_idx]:.3f}, R={rec[best_idx]:.3f}, F1={f1s[best_idx]:.3f}")

# final hard predictions with best threshold
y_pred_np = (probs > THRESH).astype(int)

# metrics
print(classification_report(y_true_np, y_pred_np, digits=4))

# (optional) confusion matrix
cm = confusion_matrix(y_true_np, y_pred_np)
print("Confusion matrix:\n", cm)

# save once
torch.save(model.state_dict(), "ai_fw_model.pt")
joblib.dump(scaler, "ai_fw_scaler.pkl")
with open("ai_fw_threshold.json", "w") as f:
    json.dump({"threshold": float(THRESH)}, f)

print("Saved model/scaler/threshold:", THRESH)

# 7) Live sniff (‡πÅ‡∏¢‡∏Å‡πÑ‡∏ß‡πâ ‚Äî ‡∏ï‡πâ‡∏≠‡∏á‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå sudo/setcap)
def safe_int(value, default=0):
    try:
        return int(value)
    except Exception:
        return default

def packet_callback(pkt):
    if IP in pkt:
        proto = pkt[IP].proto

        # ‡∏î‡∏∂‡∏á‡∏û‡∏≠‡∏£‡πå‡∏ï‡∏à‡∏≤‡∏Å‡∏ä‡∏±‡πâ‡∏ô TCP/UDP ‡∏à‡∏£‡∏¥‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î‡πÄ‡∏Ñ‡∏™ sport/dport=0
        sport = pkt[TCP].sport if TCP in pkt else (pkt[UDP].sport if UDP in pkt else 0)
        dport = pkt[TCP].dport if TCP in pkt else (pkt[UDP].dport if UDP in pkt else 0)

        src_ip = pkt[IP].src
        dst_ip = pkt[IP].dst

        try:
            srcIP = int.from_bytes(bytes(map(int, src_ip.split("."))), "big")
            dstIP = int.from_bytes(bytes(map(int, dst_ip.split("."))), "big")
        except Exception:
            return  # ‡∏Ç‡πâ‡∏≤‡∏°‡πÅ‡∏û‡πá‡∏Å‡πÄ‡∏Å‡πá‡∏ï‡∏ó‡∏µ‡πà‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö IP ‡πÅ‡∏õ‡∏•‡∏Å

        # üëâ ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡πÄ‡∏õ‡πá‡∏ô numpy ‡∏Å‡πà‡∏≠‡∏ô
        feat_np = np.array([[proto, sport, dport, srcIP, dstIP]], dtype=np.float32)
        feat_np = np.nan_to_num(feat_np, copy=False, posinf=1e9, neginf=-1e9)
        feat_np = scaler.transform(feat_np)

        feat = torch.tensor(feat_np, dtype=torch.float32)

        # infer
        with torch.no_grad():
            p = torch.sigmoid(model(feat)).item()
            decision = "ALLOW" if p > THRESH else "DENY"
            print(f"{decision} (p={p:.3f}, th={THRESH:.3f})")

        # log ‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå (‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô header ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏¢‡∏±‡∏á‡∏ß‡πà‡∏≤‡∏á)
        try:
            write_header = not os.path.exists("ai_fw_decisions.csv") or os.path.getsize("ai_fw_decisions.csv") == 0
            with open("ai_fw_decisions.csv", "a", newline="") as f:
                w = csv.writer(f)
                if write_header:
                    w.writerow(["ts","src","dst","proto","sport","dport","prob","thresh","decision"])
                w.writerow([time.time(), src_ip, dst_ip, proto, sport, dport, round(p,3), round(THRESH,3), decision])
        except Exception as e:
            print(f"[LOG WARN] {e}")

# ====== ‡∏´‡∏≤‡∏Ñ‡πà‡∏≤ threshold ‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ F1 ‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î ======
probs_np = probs.ravel()   # <-- ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô numpy 1D
prec, rec, thr = precision_recall_curve(y_true_np, probs_np)
f1s = 2 * prec * rec / (prec + rec + 1e-12)

ix = np.nanargmax(f1s)
best_thr = thr[ix] if ix < len(thr) else 0.5
print(f"Best threshold‚âà{best_thr:.3f}, P={prec[ix]:.3f}, R={rec[ix]:.3f}, F1={f1s[ix]:.3f}")

THRESH = float(best_thr)
y_pred_new = (probs_np > THRESH).astype(int)
print("F1 (best_th):", f1_score(y_true_np, y_pred_new))

# ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡πÑ‡∏î‡πâ best_thr ‡πÅ‡∏•‡πâ‡∏ß
THRESH = float(best_thr)

torch.save(model.state_dict(), "ai_fw_model.pt")
joblib.dump(scaler, "ai_fw_scaler.pkl")
with open("ai_fw_threshold.json", "w") as f:
    json.dump({"threshold": THRESH}, f)

print("‚úÖ Saved model/scaler/threshold:", THRESH)


# ====== Save model / scaler / threshold ======
torch.save(model.state_dict(), "ai_fw_model.pt")
joblib.dump(scaler, "ai_fw_scaler.pkl")
json.dump({"threshold": float(THRESH)}, open("ai_fw_threshold.json", "w"))


if __name__ == "__main__":
    try:
        # ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô iface ‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á ‡πÄ‡∏ä‡πà‡∏ô "eth0" ‡∏´‡∏£‡∏∑‡∏≠ "wlan0"
        sniff(prn=packet_callback, iface="eno2", filter="tcp or udp", timeout=30, store=False)
        # ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏:
        # - filter="ip" ‡∏à‡∏∞‡∏ä‡πà‡∏ß‡∏¢‡∏•‡∏î noise (‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞ IPv4); ‡∏à‡∏∞‡πÉ‡∏ä‡πâ "tcp" / "udp" ‡∏Å‡πá‡πÑ‡∏î‡πâ
        # - timeout=30 ‡∏Å‡∏±‡∏ô‡∏Ñ‡πâ‡∏≤‡∏á ‡∏ñ‡πâ‡∏≤‡∏≠‡∏¢‡∏≤‡∏Å‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÅ‡∏û‡πá‡∏Å‡πÄ‡∏Å‡πá‡∏ï ‡πÉ‡∏ä‡πâ count=10 ‡∏£‡πà‡∏ß‡∏°‡πÑ‡∏î‡πâ
    except PermissionError:
        print("PermissionError: ‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏±‡∏ô‡∏î‡πâ‡∏ß‡∏¢ sudo ‡∏´‡∏£‡∏∑‡∏≠ setcap ‡πÉ‡∏´‡πâ python ‡πÉ‡∏ô venv")

print(f"DENY (0) = {neg}, ALLOW (1) = {pos}") #count ALLOW & DENY





